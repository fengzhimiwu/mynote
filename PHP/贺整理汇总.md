1. 简述PHP这门编程语言的特点及优缺点，另有没有关注并了解PHP7。
- PHP开源并且简单，相对容易学习。开发速度比较快，比较适合web开发。
- 缺点是语法不太严谨，实时编译，运行速度相对比较慢
- 标量类型声明：PHP 7 中的函数的形参类型声明可以是标量了。在 PHP 5 中只能是类名、接口、array 或者 callable (PHP 5.4，即可以是函数，包括匿名函数)，现在也可以使用 string、int、float和 bool 了。
- 返回值类型声明：增加了对返回类型声明的支持。 类似于参数类型声明，返回类型声明指明了函数返回值的类型。可用的类型与参数声明中可用的类型相同。
- NULL 合并运算符：由于日常使用中存在大量同时使用三元表达式和 isset()的情况，NULL 合并运算符使得变量存在且值不为NULL， 它就会返回自身的值，否则返回它的第二个操作数。
- use 加强：从同一 namespace 导入的类、函数和常量现在可以通过单个 use 语句 一次性导入了
- 匿名类：现在支持通过new class 来实例化一个匿名类

2. LNMP和LAMP有什么区别。
区别是nginx作为web服务器，比apache使用资源更少。支持并发更多，效率更好。

3. 简述一下php-fpm，如何确定一台机器应该开启多少个php进程。
PHP-fpm是fastcgi的进程管理器，是php里php-cgi的管理器，php-cgi只是个cgi程序，自己本身只能解析请求，返回结构，不会进程管理。
php -ef | grep "php-fpm" |wc -l

4. 简述一下闭包。
- 个人理解闭包是指函数里面定义一个私有的函数，可以调用父函数里的变量
- 一个外部函数执行完毕后，由于其内部函数被外部引用，导致其作用域的变量继续存活，而不能在函数执行完毕后销毁，包含这些变量的那个对象就叫闭包。

5. session和cookie的区别。如何共享分布式集群下的session。
  session是存储在服务器端，存储的用户的信息
  cookie存储在客户端，session需要通过cookie传递sessionid确定当前登录信息
  共享分布式session，多个机器同步session，或者单独一台session服务器，所有session
  都存储到共享session服务器

  

8. 简术一下nosql及应用场景。
memcache 特点
- 速度快
- 缺乏安全验证
- 重启数据消失
- 有效期（默认30天，可以通过改源码）
- 适合大量cpu低内存高的机器搭建集群
- 个体独立，由客户端实现分布式算法
redis 缓存数据，高并发，存储数据
mongodb 存储海量数据
elaticsearch 日志分析，存储数据，搜索
- mongodb设置密码
- 配置访问ip白名单

9. 简述短连接和长连接的特点及应用场景，PHP应该如何选择。
长连接主要是长时间保持客户端与服务器端的状态。长连接主要是用于少数客户端与服务端的频繁通信。
短连接常用于web应用，响应完成立即断开

10. web开发中一般有哪些安全问题并简述一下原理和处理方式。
- xss跨站脚本攻击
- csrf跨站请求伪造（cross-site request forgery）
- csrf实际上是用户登录网站a，然后登录钓鱼网站b的时候，不知情的情况下访问了b提供的访问a的链接。
- 防御方法
- 1.http refer,refer里记录来源网址，但是有的浏览器（ie ff2）可以自定义修改
- 2.请求地址里加上token验证，token存在session中，每次请求都带上token，验证用户合法性。缺点是改动量大，token也有可能会被获取到，有些论坛允许用户添加自己的网站链接，有可能也会在连接上带上用户token。
- 3.http头里增加自定义属性，通过xmlhttprequest类添加

11. 简述一下数据库的分表方式及应用场景。
水平分表：适用于单表数据量庞大，根据某种规则把数据分到不同的数据表里，降低单表数据量，优化查询
垂直分表：将热点字段和不必须的字段拆分到两张表里
垂直水平拆分：将不同业务的表拆分到不同的库里，减少单库压力

12. 数据库索引是什么？一般有几种类型？
普通索引，唯一索引，主键索引，组合索引，全文索引

13. 简述一下你所知道的html5新特性。

14. 简述一下php5、php7 zval struct有什么特点，如果需要操作数组，他们的处理方式有什么不同？

15. 常见的js开源库里都有声明use strict，有什么作用。
严格模式，让解释器以更严格的方式检查代码。js里一些特性没法使用。

16. 一些常用的设计模式
- 单例模式
- 工厂模式
- 策略模式
- 观察者模式
- 依赖注入
- 装饰器
- 迭代器
- 对象池

18.HTTPS、HTTP、TCP/UDP、IP
https和http是应用层协议
tcp和udp是传输层协议
https是加密的

19.是否了解响应式布局，其实现原理是什么？
根据浏览窗口大小设置不同的样式

20. 简述Mongo的优化
首先设置密码，建立适当的索引，注意磁盘容量

21. 简述Mysql的优化
建立索引
单条数据查询用limit1
数据库引擎
explain提前查看语句性能

22. 简述Redis的抖动
缓存击穿：恶意访问不存在的数据，导致数据库异常
缓存雪崩：同一时间大量键过期，导致请求落到数据库，可以给缓存设置一个随机过期时间

23. 简述php的错误机制
- error_reporting(E_ALL);
- ini_set('display_errors', 'On');
- try catch finally
- set_error_handle //处理默认notice，warning等错误
- register_shutdown_function
```
register_shutdown_function(function(){
    if($error = error_get_last()){
        print_r($error);
    }
}
```

24. 简述Nginx的优化 反向代理
work_process 8 nginx进程数，建议按照cpu数目来指定
epoll 事件处理模型
keepalive_timeout 连接的超时时间
proxy_pass

25. 简述HTTP协议
超文本传输协议，应用层协议，无状态的，客户端请求，服务端响应

26. ASCII、Unicode、GBK、UTF-8
ascii英文编码，gbk是中文编码，unicode全世界统一编码，utf-8基于unicode,unicode比较浪费带宽和
硬盘，所以将unicode编码解码一套编码规则，就是utf-8

27. 数据结构和算法

28. 列举一些常用的Linux命令
   grep find chmod chown zip unzip top uptime cat sed awk 

   

31. MIME是什么，列举一些常见的类型
mime类型是多用途互联网邮件扩展类型

32. 如何把文件的权限设定成777，其中每个7代表什么？
chmod -R 777 ./*
从左至右用0-9表示10个字符，第0位确定文件类型，
第1-3位确定属主权限拥有该文件的权限（该文件的所有者的权限），
第4-6位确定属组权限拥有该文件的权限（所有者的同组用户），
第7-9位确定其他用户拥有该文件的权限。
用数字来代表各个权限，则：

    读，权限是二进制的100，十进制是4；

    写，权限是二进制的010，十进制是2；

    执行，权限是二进制的001，十进制是1；

即：各权限的对应数字为：r:4，w:2，x:1



34. 例代码：
       $a = array('abcde');
       $a[] = $a;
       unset($a);
       这段代码在较老的php版本中（<5.3）运行会出现什么问题？ php之后的版本是如何改进的？
- 

>

39. 简述一下session的生命周期
session.save_path
session.save_handle

40. 使用过哪些PHP框架，简单做下介绍和评价

41.如何处理tcp粘包问题
- https://www.jianshu.com/p/bb1377163ca7
- TCP 是流式协议没有消息边界，客户端向服务器端发送一次数据，可能会被服务器端分成多次收到。
- 客户端向服务器端发送多条数据。服务器端可能一次全部收到。
保证传输的可靠性，顺序。
- TCP拥有拥塞控制，所以数据包可能会延后发送。
- TCP粘包
- 介绍
- TCP 粘包是指发送方发送的若干包数据 到 接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。
- 原因
- 发送方：发送方需要等缓冲区满才发送出去，造成粘包
- 接收方：接收方不及时接收缓冲区的包，造成多个包接收
- swoole处理粘包
- EOF结束协议：
- EOF切割需要遍历整个数据包的内容，查找EOF，因此会消耗大量CPU资源。上手比较简单
- 固定包头+包体协议
- 长度检测协议，只需要计算一次长度，数据处理仅进行指针偏移，性能非常高

42、很多人在网上或者自己工作中都碰到过  “锟斤拷雮傡锟斤拷...” 类似的东西，简述一下他们出现的原理和解决办法。
- <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
- header("content-type:text/html;charset=utf-8");
- mysql_query('SET NAMES UTF8');

43、在php手册中，经常能看到xxx函数是二进制安全的，比如转换大小写的strtoupper、strtolower俩函数，你如何理解“二进制安全”？
- 因为有了对字符串长度定义len, 所以在处理字符串时候不会以零值字节(\0)为字符串结尾标志.
- 二进制安全就是输入任何字节都能正确处理, 即使包含零值字节.
- redis不像C语言那样,使用'\0'作为判定一个字符串的结尾,而是使用了独立的len,这样可以保证即使存储的数据中有'\0'这样的字符,它也是可以支持读取的.

42. myisam存储引擎
- 查询表级锁的争用情况
- table_lockes_waited,table_locks_immediate
- show status like 'table%' 查看
- 两个相除大于5000说明有问题
- 读锁不影响读操作，影响写操作
- 写锁会影响所有读写操作
- 
- myisam锁调度
- 默认是写比较重要，可以设置 set low_priority_updates =1 使更新请求优先降级
- myisam存储引擎索引
- myisam默认使用b-tree,只把索引载入内存
- myisam字符串索引采用增量保存，例如第一个索引值是perform,第二个是performance,在索引文件中第二个索引被保存为7，ance,减少索引的尺寸
- myisam保存索引的状态在磁盘里，每次执行analyze table会更新这个信息
- 索引长期运行会产生碎片，一种是一行数据保存在不同的数据段，一种是连续的表空间或行在磁盘上被分散的保存

>innodb 存储引擎
- 行锁争用情况
- show status like 'innodb_row_lock%'
- +-------------------------------+-------+
| Variable_name                 | Value |
+-------------------------------+-------+
| Innodb_row_lock_current_waits | 0     |
| Innodb_row_lock_time          | 0     |
| Innodb_row_lock_time_avg      | 0     |
| Innodb_row_lock_time_max      | 0     |
| Innodb_row_lock_waits         | 0     |
+-------------------------------+-------+
- 


>php 错误处理
- try catch finally
- set_error_handle //处理默认notice，warning等错误
- register_shutdown_function
```
register_shutdown_function(function(){
    if($error = error_get_last()){
        print_r($error);
    }
}
```
>trait特性
- 主要用来解决单继承引起的代码复用问题
- 类中使用trait类似于include
- trait支持所有修饰符例如final,static,abstract
- trait不能通过new实例化
- trait中的方法冲突可以通过insteadof或者as 关键词解决，通过as还可以修改访问权限
- use atrait, btrait;
- trait里也可以使用trait
- insteadof代替的意思，as 别名的意思
```
use A, B {
        B::smallTalk insteadof A;
        A::bigTalk insteadof B;
        B::bigTalk as talk;
    }
```
- reflaction 反射。反射的意思是提取出关于类，方法，属性参数等的详细信息，包括注释
- 

>乐观锁和悲观锁的意思
- 同一时间并发对同一个数据对象进行更新的问题，叫做丢失更新
- 乐观锁操作方法是在数据后面加一个version字段，当需要更新的时候，先查出version的值，更新的时候where条件判断version是否改变，如果没改变，说明没有冲突
- 悲观锁是在mysql事务基础上，在select sql后面加一个for update,确保锁住当前行
- 要使用悲观锁，必须关闭mysql数据库的自动提交属性，因为MySQL默认使用autocommit模式，也就是当你执行一个更新操作后，MySQL会立即将结果进行提交
- 共享锁，事务中给语句后面添加 lock in share mode
- 排它锁，事务中给语句添加 for update
- 

>悲观锁特点
- 为数据处理的安全提供了保证
- 效率上，由于处理加锁的机制会让数据库产生额外开销，增加产生死锁机会
- 在只读型事务中由于不会产生冲突，也没必要使用锁，这样会增加系统负载，降低并行性
- 

>redis 持久化机制和线上环境容灾
- https://blog.csdn.net/zh15732621679/article/details/80307827
- https://www.cnblogs.com/chenhaoyu/p/10837723.html //redis 实战操作RDB和AOF快照持久化
- rdb 和 aof 两种持久化机制
- rdb 原理每隔一段时间生成redis内存中的数据的一份完整的快照
- 触发持久化的机制有手动触发和自动触发
- 手动触发是执行bgsave命令，bgsave会fork一个子进程，在子进程里备份数据
- 自动触发，/etc/redis/6379.conf文件,手动配置检查点,一条save配置代表一个检查点，redis默认的机制是RDB所以不涉及开启或不开启。例如,我想每隔5s,只要有一条数据更新就生成快照 save 5 1
- AOF持久化机制。
- 原理有数据写入redis,redis自身就会将数据写入aof日志文件,redis并不是直接写入aof文件,而是先写到os cache,然后到一定时间再从os cache会触发操作系统的fsync操作写到磁盘 AOF会无限制的增加吗? 不会,redis中的数据是有一定限量的,不可能说redis内存中的数据无限增长,进而导致AOF无限增长,内存大小是一定的,到一定时候,redis就会用缓存淘汰算法,LRU,自动将一部分数据从内存中给清除,AOF是存放每条写命令的,所以会不断的膨胀,当大到一定的时候,AOF做rewrite操作,将AOF变得小一些,然后将旧的删掉 例如,当redis进行了清理,清除了一部分数据,AOF量到一定程度时,会rewrite,根据redis中新的数据进行rewrite,从而将aof变小,然后将旧的删掉 
- 手动触发。执行bgrewriteaof命令即可
- 自动触发 
- 由于redis默认的是RDB的持久化方式,AOF的方式默认是关闭的,所以,我们需要手动开启,我们打开/etc/redis/6379.conf配置文件
a.打开AOF机制  appendonly yes
- 配置rewrite
在/etc/redis/6379.conf文件中有两个配置,auto-aof-rewrite-percentage和auto-aof-rewrite-min-size
第一条命令的意思是,当aof日志文件中的大小大于上一次的一倍了,那就执行rewrite
第二条意思是,就算满足了第一条的条件,但是还是需要和auto-aof-rewrite-min-size配置的值进行比较,当aof的大小大于64m时才会进行rewrite操作
- auto-aof-rewrite-percentage 100
- auto-aof-rewrite-min-size 64mb
- OF的三种写入方式,使用默认的everysec即可,即,每秒写入一次
```
# appendfsync always
appendfsync everysec
# appendfsync no
```
>数据恢复方案
- a.如果是redis进程挂掉，那么重启redis进程即可，直接基于AOF日志文件恢复数据
- b.如果是redis进程所在机器挂掉，那么重启机器后，尝试重启redis进程，尝试直接基于AOF日志文件进行数据恢复
- c.如果redis当前最新的AOF和RDB文件出现了丢失/损坏，那么可以尝试基于该机器上当前的某个最新的RDB数据副本进行数据恢复
①停止redis(命令是redis-cli shutdown),
②在配置文件中关闭aof: appendonly no
③拷贝rdb日志备份到/var/redis/6379目录下
④启动redis(命令是,先到目录/etc/init.d/目录下, ./redis_6379)
⑤尝试get一个key,确认数据恢复
⑥命令热修改redis配置,使用redis-cli连接redis,使用命令redis config set appendonly yes打开aof方式,这样aof和rdb数据就一致了
⑦手动修改6379.conf配置文件中appendonly为yes,因为热修改暂时不会写到配置文件中,所以需要手动修改,然后启动redis,再次确认数据恢复
- d.如果当前机器上的所有RDB文件全部损坏，那么从远程的云服务上拉取最新的RDB快照回来恢复数据
- c.如果是发现有重大的数据错误,就找最新的并且无错的进行恢复
- 如果需要恢复数据，只需将备份文件 (dump.rdb) 移动到 redis 安装目录并启动服务即可。获取 redis 目录可以使用 CONFIG 命令
```
redis 127.0.0.1:6379> CONFIG GET dir
1) "dir"
2) "/usr/local/redis/bin"
```
>redis常见性能问题和解决方案
- Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件
- 如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次
- 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内
- 尽量避免在压力很大的主库上增加从库
- 主从复制不要用图状结构，用单向链表结构更为稳定，即：Master <- Slave1 <- Slave2 <- Slave3...
这样的结构方便解决单点故障问题，实现Slave对Master的替换。如果Master挂了，可以立刻启用Slave1做Master，其他不变。
- Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。
- Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。
- Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。
>MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据
- redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。redis 提供 6种数据淘汰策略：
- voltile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
- volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
- volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
- allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰
- allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰
- no-enviction（驱逐）：禁止驱逐数据
- 
>


>php中类的使用
>
>- pdo   Php data object
- 静态方法中，只能调用静态变量，而不能调用普通变量，但是普通方法可以调用静态变量。
- 静态成员可以不需要实例化对象，当对象销毁时，仍然保存被修改的静态数据。因为他第一次被加载的时候就已经分配了内存空间，所以静态成员速度会快一些，但是如果声明太多，空间就会一直被占用？
- Final类不能被继承。final方法不能被重写
抽象类是不能被实例的类，只能作为父类来使用，抽象类至少包含一个抽象方法，而且没有方法体，只能在子类中完成功能实现，是使用abstract来修饰的。
- Php只支持单继承，要是实现多继承，需要使用接口，通过interface来修饰，不要以public以外的关键字来修饰接口中的类成员，对于方法，不写关键字也可以。
- 子类通过implements来实现接口，多个接口用逗号连接，而且所有未实现的方法需要在子类中全部实现。
- 


>查询优化
- https://tech.meituan.com/2014/06/30/mysql-index.html
>建索引的几大原则
- 1.最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。
- 2.=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。
- 3.尽量选择区分度高的列作为索引，区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录。
- 4.索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’)。
- 5.尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。

>慢查询优化基本步骤
- explain 这里需要强调rows是核心指标，绝大部分rows小的语句执行一定很快（有例外，下面会讲到）。所以优化语句基本上都是在优化rows
- 0.先运行看看是否真的很慢，注意设置SQL_NO_CACHE
- 1.where条件单表查，锁定最小返回记录表。这句话的意思是把查询语句的where都应用到表中返回的记录数最小的表开始查起，单表每个字段分别查询，看哪个字段的区分度最高
- 2.explain查看执行计划，是否与1预期一致（从锁定记录较少的表开始查询）
- 3.order by limit 形式的sql语句让排序的表优先查
- 4.了解业务方使用场景
- 5.加索引时参照建索引的几大原则
- 6.观察结果，不符合预期继续从0分析


>Innodb中的事务隔离级别和锁的关系
- https://tech.meituan.com/2014/08/20/innodb-lock.html

>事务隔离级别
- 读未提交 允许脏读，也就是可能读取到其他会话中未提交事务修改的数据
- 读已提交 read commited 只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别 (不重复读)
- 可重复读 repeatable read 可重复读。在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别。在SQL标准中，该隔离级别消除了不可重复读，但是还存在幻象读
- 可串行化 完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞
- 很多人容易搞混不可重复读和幻读，确实这两者有些相似。但不可重复读重点在于update和delete，而幻读的重点在于insert。
- 
>mvcc原理
- 结论：可重复度级别下，事务修改的时候，读取的是undolog里最新提交的commit数据。读取的时候，读的是当前事务id之前提交的和当前提交的版本的数据。
- 每个事务执行都会放到undolog里，每个log都有递增的id来表示。当读取的时候，先确定当前事务可读取的id的范围，再来确定当前能读取到的数据
- 

>分布式锁原理
- https://www.jianshu.com/p/31d3de863ff7
- https://www.jianshu.com/p/a1ebab8ce78a
- 在分布式系统环境下，一个方法在同一时间只能- 被一个机器的一个线程执行
- 高可用的获取锁与释放锁
- 高性能的获取锁与释放锁
- 具备可重入特性（可理解为重新进入，由多于一个任务并发使用，而不必担心数据错误）
- 具备锁失效机制，防止死锁
- 具备非阻塞锁特性，即没有获取到锁将直接返回获取锁失败
- Memcached：利用 Memcached 的 add 命令。此命令是原子性操作，只有在 key 不存在的情况下，才能 add 成功，也就意味着线程得到了锁。
- Redis：和 Memcached 的方式类似，利用 Redis 的 setnx 命令。此命令同样是原子性操作，只有在 key 不存在的情况下，才能 set 成功。

>redis 分布式锁
- 加锁。setnx（lock_sale_商品ID，1）。当一个线程执行 setnx 返回 1，说明 key 原本不存在，该线程成功得到了锁；当一个线程执行 setnx 返回 0，说明 key 已经存在，该线程抢锁失败。
- 解锁。del（lock_sale_商品ID）
- 锁超时。锁超时是什么意思呢？如果一个得到锁的线程在执行任务的过程中挂掉，来不及显式地释放锁，这块资源将会永远被锁住（死锁），别的线程再也别想进来。所以，setnx 的 key 必须设置一个超时时间，以保证即使没有被显式释放，这把锁也要在一定时间后自动释放。setnx 不支持超时参数，所以需要额外的指令。 expire（lock_sale_商品ID， 30）
```
if（setnx（lock_sale_商品ID，1） == 1）{
    expire（lock_sale_商品ID，30）
    try {
        do something ......
    } finally {
        del（lock_sale_商品ID）
    }
}
```
>存在的致命性
- setnx 和 expire 的非原子性。setnx 刚执行成功，还未来得及执行 expire 指令，节点 1 挂掉了。锁不能释放
- 怎么解决呢？setnx 指令本身是不支持传入超时时间的，set 指令增加了可选参数，伪代码如下。set（lock_sale_商品ID，1，30，NX）。redis从2.6.12版本开始，SET命令才支持这些参数
- SET key value [EX seconds] [PX milliseconds] [NX|XX]
- set test 555 ex 5 nx
- ex 过期秒，px 过期毫秒
- EX second ：设置键的过期时间为 second 秒。 SET key value EX second 效果等同于 SETEX key second value 。
- PX millisecond ：设置键的过期时间为 millisecond 毫秒。 SET key value PX millisecond 效果等同于 PSETEX key millisecond value 。
- NX ：只在键不存在时，才对键进行设置操作。 SET key value NX 效果等同于 SETNX key value 。
- XX ：只在键已经存在时，才对键进行设置操作。
- TTL rediskey //获取键过期时间
- http://doc.redisfans.com/string/set.html
- del 导致误删
- 如果某些原因导致线程 A 执行的很慢很慢，过了 30 秒都没执行完，这时候锁过期自动释放，线程 B 得到了锁
- 可以在 del 释放锁之前做一个判断，验证当前的锁是不是自己加的锁。至于具体的实现，可以在加锁的时候把当前的线程 ID 当做 value，并在删除之前验证 key 对应的 value 是不是自己线程的 ID
- 加锁
```
String threadId = Thread.currentThread().getId()
set（key，threadId ，30，NX）
```
- 解锁
```
if（threadId .equals(redisClient.get(key))）{
    del(key)
}
```
- 我们可以让获得锁的线程开启一个守护线程，用来给快要过期的锁“续航”




>redis rdb恢复要点
- 必须 shutdown
- rdb恢复目录可以通过 config get dir查看
- 必须appendonly = no
- 

>mysql join用法
- https://blog.csdn.net/u012410733/article/details/63684663
- join 笛卡尔积，两表关联，把左表的列和右表的列通过笛卡尔积的形式表达出来。
- left join 两表关联，左表全部保留，右表关联不上用null表示。
- right join 右表全部保留，左表关联不上的用null表示。
- inner join 两表关联，保留两表中交集的记录。
- select * from t1 left join t2 on t1.id = t2.id where t2.id is null; 两表关联，查询左表独有的数据。
- select * from t1 right join t2 on t1.id = t2.id where t1.id is  null; 两表关联，查询右表独有的数据。
- union 全连接 select * from t1 left join t2 on t1.id = t2.id union select * from t1 right join t2 on t1.id = t2.id;两表关联，查询它们的所有记录。
- 两表关联，取并集然后去交集。select * from t1 left join t2 on t1.id = t2.id where t2.id is null union select * from t1 right join t2 on t1.id = t2.id where t1.id is null;
- 

>int,datetime,timestamp效率比较
- https://www.jianshu.com/p/b22ac1754372
- https://blog.csdn.net/adsadadaddadasda/article/details/78933784
- https://blog.csdn.net/wuzekai2010/article/details/53149133
- 在InnoDB存储引擎下，通过时间范围查找，性能bigint > datetime > timestamp
- 在InnoDB存储引擎下，通过时间排序，性能bigint > timestamp > datetime
- 如果需要对时间字段进行操作(如通过时间范围查找或者排序等)，推荐使用bigint，如果时间字段不需要进行任何操作，推荐使用timestamp，使用4个字节保存比较节省空间，但是只能记录到2038年记录的时间有限
- 读取效率：int > timestamp > datetime
- 
>读写分离延迟
- gtid 方案。事务执行完成后获取事务的gtid。随意选择一个从库 执行 select wait_for_executed_gtid_set(gtid,1)。如果返回0就在从库执行查询，否则去主库查询
- 需要加参数 session_track_gtids 设置为own_gtid,然后通过api接口mysql_session_track_get_first 从返回包解析出 gtid的值

>redis 命令列表
- del 删除给定的一个或多个 key 。不存在的 key 会被忽略。返回被删除key的数量。O(N)， N 为被删除的 key 的数量。删除单个字符串类型的 key ，时间复杂度为O(1)。删除单个列表、集合、有序集合或哈希表类型的 key ，时间复杂度为O(M)， M 为以上数据结构内的元素数量。
- dump 。序列化给定 key ，并返回被序列化的值，使用 RESTORE 命令可以将这个值反序列化为 Redis 键
- exists 检查给定 key 是否存在。若 key 存在，返回 1 ，否则返回 0 。
- expire key seconds
设置过期时间。设置成功返回 1 
- expireat key timestamp 设置过期时间，后面跟的是unix 时间戳
- KEYS pattern 查找所有符合给定模式 pattern 的 key。
- ttl -2表示不存在key -1 表示永不过期
```
KEYS * 匹配数据库中所有 key 。
KEYS h?llo 匹配 hello ， hallo 和 hxllo 等。
KEYS h*llo 匹配 hllo 和 heeeeello 等。
KEYS h[ae]llo 匹配 hello 和 hallo ，但不匹配 hillo 。
KEYS 的速度非常快，但在一个大的数据库中使用它仍然可能造成性能问题，如果你需要从一个数据集中查找特定的 key ，你最好还是用 Redis 的集合结构(set)来代替。
```
- migrate host port key destination-db timeout [COPY] [REPLACE] 迁移实例key
- MOVE key db 将当前数据库的 key 移动到给定的数据库 db 当中
- object subcommand [arguments [arguments]]
OBJECT 命令允许从内部察看给定 key 的 Redis 对象
```
OBJECT 命令有多个子命令：

OBJECT REFCOUNT <key> 返回给定 key 引用所储存的值的次数。此命令主要用于除错。
OBJECT ENCODING <key> 返回给定 key 锁储存的值所使用的内部表示(representation)。
OBJECT idletime <key> 返回给定 key 自储存以来的空转时间(idle， 没有被读取也没有被写入)，以秒为单位。
```
- persist key 移除key的时间，转换为永久key
- pexpire p-expire跟expire类似，存储毫秒
- pexpireat 毫秒的时间戳
- pttl 返回毫秒生存时间
- randomkey 随机返回一个key
- rename key newkey 修改key名字
- renamenx key newkey 当且仅当 newkey 不存在时，将 key 改名为 newkey 
- restore key ttl serialized-value 反序列化给定的序列化值，并将它和给定的 key 关联。个人理解可以将反序列化的值赋值给一个新key
- sort key [BY pattern] [LIMIT offset count] [GET pattern [GET pattern ...]] [ASC | DESC] [ALPHA] [STORE destination] 返回或保存给定列表、集合、有序集合 key 中经过排序的元素
- type key 返回 key 所储存的值的类型
- scan cursor [MATCH pattern] [COUNT count]
```
SCAN 命令用于迭代当前数据库中的数据库键。
SSCAN 命令用于迭代集合键中的元素。
HSCAN 命令用于迭代哈希键中的键值对。
ZSCAN 命令用于迭代有序集合中的元素（包括元素成员和元素分值）。
```
>redis 字符串
- APPEND key value
```
如果 key 已经存在并且是一个字符串， APPEND 命令将 value 追加到 key 原来的值的末尾。
如果 key 不存在， APPEND 就简单地将给定 key 设为 value ，就像执行 SET key value 一样。
```
- bitcount key [start] [end]计算给定字符串中，被设置为 1 的比特位的数量。
```
Bitmap 对于一些特定类型的计算非常有效。

假设现在我们希望记录自己网站上的用户的上线频率，比如说，计算用户 A 上线了多少天，用户 B 上线了多少天，诸如此类，以此作为数据，从而决定让哪些用户参加 beta 测试等活动 —— 这个模式可以使用 SETBIT 和 BITCOUNT 来实现。

比如说，每当用户在某一天上线的时候，我们就使用 SETBIT ，以用户名作为 key ，将那天所代表的网站的上线日作为 offset 参数，并将这个 offset 上的为设置为 1 。

举个例子，如果今天是网站上线的第 100 天，而用户 peter 在今天阅览过网站，那么执行命令 SETBIT peter 100 1 ；如果明天 peter 也继续阅览网站，那么执行命令 SETBIT peter 101 1 ，以此类推。

当要计算 peter 总共以来的上线次数时，就使用 BITCOUNT 命令：执行 BITCOUNT peter ，得出的结果就是 peter 上线的总天数。
可用于打卡统计天数
```
- bitop operation destkey key [key ...] 对一个或多个保存二进制位的字符串 key 进行位元操作，并将结果保存到 destkey 上。
- decr key 数字减1
- decrby key decrement 将 key 所储存的值减去减量 decrement 如果 key 不存在，那么 key 的值会先被初始化为 0 ，然后再执行 DECRBY 操作
- get key 返回 key 所关联的字符串值
- getbit key offset 对 key 所储存的字符串值，获取指定偏移量上的位(bit)。
- getrange key start end 字符串截取，2.0之前版本叫做substr
- getset key value 将给定 key 的值设为 value ，并返回 key 的旧值(old value)。
- incr key 将 key 中储存的数字值增一
- incrby key increment 增加相应数量的值
- incrbyfloat key increment 增加浮点数,也可以是负数
- mget key [key ...] 返回所有(一个或多个)给定 key 的值。复杂度o(n)
- mset key value [key value ...] 同时设置一个或多个 key-value 对
- msetnx key value [key value ...] 同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在。
- psetex key milliseconds value 这个命令和 SETEX 命令相似，但它以毫秒为单位设置 key 的生存时间，而不是像 SETEX 命令那样，以秒为单位。
- setbit key offset value 对 key 所储存的字符串值，设置或清除指定偏移量上的位(bit)。
- SETEX key seconds value 将值 value 关联到 key ，并将 key 的生存时间设为 seconds (以秒为单位)。
- SETNX key value 将 key 的值设为 value ，当且仅当 key 不存在。
- setrange key offset value 用 value 参数覆写(overwrite)给定 key 所储存的字符串值，从偏移量 offset 开始
- 

>hash表
- hdel key field [field ...] 删除哈希表 key 中的一个或多个指定域，不存在的域将被忽略。
```
在Redis2.4以下的版本里， HDEL 每次只能删除单个域，如果你需要在一个原子时间内删除多个域，请将命令包含在 MULTI / EXEC 块内。
```
- hexists key field 判断hash里有没有某个key存在
- hget key field 返回哈希表 key 中给定域 field 的值。
- hgetall key 返回哈希表 key 中，所有的域和值。
- hincrby key field increment 给某个int类型增加或减少数字.如果 key 不存在，一个新的哈希表被创建并执行 HINCRBY 命令
- hincrbyfloat key field increment 为哈希表 key 中的域 field 加上浮点数增量 increment 。
- hkeys key 返回哈希表 key 中的所有域。
- hlen key 返回哈希表 key 中域的数量。
- hmget key field [field ...] 返回哈希表 key 中，一个或多个给定域的值。
- hmset key field value [field value ...] 同时将多个 field-value (域-值)对设置到哈希表 key 中。
- hset key field value 将哈希表 key 中的域 field 的值设为 value 。
- hsetnx key field value 将哈希表 key 中的域 field 的值设置为 value ，当且仅当域 field 不存在。
- hvals key 返回哈希表 key 中所有域的值
- hscan
- 

>list liebiao 
- blpop|brpop key [key ...] timeout 它是 LPOP 命令的阻塞版本，当给定列表内没有任何元素可供弹出的时候，连接将被 BLPOP 命令阻塞，直到等待超时或发现可弹出元素为止。timeout=0,一直堵塞。他会轮询你当前的key，当所有的为nil时再堵塞。b是blocking的意思
- brpoplpush | rpoplpush source destination timeout 将列表source最右边元素弹出放到destination列表的最左边。b有堵塞功能，如果source和destination相同，则列表中的表尾元素被移动到表头，并返回该元素，称为列表的旋转
- lindex key index 返回列表 key 中，下标为 index 的元素,也可以使用负数下表
- linsert key before|after pivot value 
```
将值 value 插入到列表 key 当中，位于值 pivot 之前或之后。
当 pivot 不存在于列表 key 时，不执行任何操作。
当 key 不存在时， key 被视为空列表，不执行任何操作。
如果 key 不是列表类型，返回一个错误。
LINSERT mylist BEFORE "World" "There"
```
- llen key 返回列表长度
- lpushx key value 当列表不为空且列表存在才插入
- lrange key start stop 返回列表指定区间的元素
- lrem key count value 根据参数 count 的值，移除列表中与参数 value 相等的元素。
```
count > 0 : 从表头开始向表尾搜索，移除与 value 相等的元素，数量为 count 。
count < 0 : 从表尾开始向表头搜索，移除与 value 相等的元素，数量为 count 的绝对值。
count = 0 : 移除表中所有与 value 相等的值。
```
- lset key index value 将列表 key 下标为 index 的元素的值设置为 value 。
- ltrim key start stop 对一个列表进行修剪(trim)，就是说，让列表只保留指定区间内的元素，不在指定区间之内的元素都将被删除。
- 

>set集合
- sadd key member [member ...] 将一个或多个 member 元素加入到集合 key 当中，已经存在于集合的 member 元素将被忽略。
- scard key 返回集合中的基数
- sdiff key [key ...] 返回一个集合的全部成员，该集合是所有给定集合之间的差集。
- sdiffstore | sinterstore destination key [key ...] 这个命令的作用和 SDIFF 类似，但它将结果保存到 destination 集合，而不是简单地返回结果集。
- sinter key [key ...] 返回一个集合的全部成员，该集合是所有给定集合的交集。
- sismember key member 判断 member 元素是否集合 key 的成员
- smembers 返回集合 key 中的所有成员。
- smove source destination member 将 member 元素从 source 集合移动到 destination 集合。
- spop key 移除并返回集合中的一个随机元素。
- srandmember key [count]
```
如果 count 为正数，且小于集合基数，那么命令返回一个包含 count 个元素的数组，数组中的元素各不相同。如果 count 大于等于集合基数，那么返回整个集合。
如果 count 为负数，那么命令返回一个数组，数组中的元素可能会重复出现多次，而数组的长度为 count 的绝对值。
```
- srem key member [member ...] 移除集合 key 中的一个或多个 member 元素，不存在的 member 元素会被忽略。
- sunion key [key ...] 返回一个集合的全部成员，该集合是所有给定集合的并集。自动去重的
- sunionstore destination key [key ...] 集合存储
- scan
- 

>有序集合
- zadd key score member [[score member] [score member] ...] 将一个或多个 member 元素及其 score 值加入到有序集 key 当中。
- zcard key 返回有序集 key 的基数。
- zcount key min max 返回有序集 key 中， score 值在 min 和 max 之间(默认包括 score 值等于 min 或 max )的成员的数量。
- zincrby key increment member 为有序集 key 的成员 member 的 score 值加上增量 increment 。也可以是负数
- zrange key start stop [WITHSCORES] 返回有序集 key中，指定区间内的成员。其中成员的位置按 score 值递增(从小到大)来排序。
- zrangebyscore key min max [WITHSCORES] [LIMIT offset count] 返回有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。有序集成员按 score 值递增(从小到大)次序排列。
```
min 和 max 可以是 -inf 和 +inf ，这样一来，你就可以在不知道有序集的最低和最高 score 值的情况下，使用 ZRANGEBYSCORE 这类命令。
ZRANGEBYSCORE salary -inf +inf               # 显示整个有序集
```
- zrank key member 返回有序集 key 中成员 member 的排名。其中有序集成员按 score 值递增(从小到大)顺序排列。排名最低是0
- zrem key member [member ...] 移除有序集 key 中的一个或多个成员，不存在的成员将被忽略
- zremrangebyrank key start stop 
移除有序集 key 中，指定排名(rank)区间内的所有成员。
- zremrangebyscore key min max 移除有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。
- zrevrange key start stop [WITHSCORES] 返回有序集 key 中，指定区间内的成员。其中成员的位置按 score值递减(从大到小)来排列。rev 就是逆序，reverse的意思
- zrevrangebyscore key max min [WITHSCORES] [LIMIT offset count] 返回有序集 key 中， score 值介于 max 和 min 之间(默认包括等于 max 或 min )的所有的成员。有序集成员按 score 值递减(从大到小)的次序排列。
- zrevrank key member 返回有序集 key 中成员 member 的排名。其中有序集成员按 score 值递减(从大到小)排序。
- zscore key member 返回有序集 key 中，成员 member 的 score 值。
- zunionstore destination numkeys key [key ...] [WEIGHTS weight [weight ...]] [AGGREGATE SUM|MIN|MAX] 
```
计算给定的一个或多个有序集的并集，其中给定 key 的数量必须以 numkeys 参数指定，并将该并集(结果集)储存到 destination 。
默认情况下，结果集中某个成员的 score 值是所有给定集下该成员 score 值之 和 。
WEIGHTS
使用 WEIGHTS 选项，你可以为 每个 给定有序集 分别 指定一个乘法因子(multiplication factor)，每个给定有序集的所有成员的 score 值在传递给聚合函数(aggregation function)之前都要先乘以该有序集的因子。
如果没有指定 WEIGHTS 选项，乘法因子默认设置为 1 。
AGGREGATE
使用 AGGREGATE 选项，你可以指定并集的结果集的聚合方式。
默认使用的参数 SUM ，可以将所有集合中某个成员的 score 值之 和 作为结果集中该成员的 score 值；使用参数 MIN ，可以将所有集合中某个成员的 最小 score 值作为结果集中该成员的 score 值；而参数 MAX 则是将所有集合中某个成员的 最大 score 值作为结果集中该成员的 score 值。
```
- zinterstore destination numkeys key [key ...] [WEIGHTS weight [weight ...]] [AGGREGATE SUM|MIN|MAX] 计算给定的一个或多个有序集的交集，其中给定 key 的数量必须以 numkeys 参数指定，并将该交集(结果集)储存到 destination 。
- zscan
- 

>geohash 算法，给经纬度编码，计算周边信息

>一致性哈希算法
- https://www.jb51.net/article/137523.htm
- 主要解决问题分布式的负载问题，即使新增或者删除节点，影响的只是一部分的数据负载。减轻系统的压力
- 
>红包分配方法
- https://blog.csdn.net/dragon_18/article/details/86378979

>redis scan 用法
- scan cursor match * count 200
- 实际上scan后面的count不是要输出的数量。而是要迭代的所有key里的个数。我的理解就是redis里有10000个key。如果我想一次性全部scan出来，我必须把这个count大于redis里所有的key的个数。就类似于o(n)遍历，只不过scan不堵塞，是迭代性的，类似于php和python的协程 yield。
- cursor比较有意思。当你后面的count数量太小的时候，或者可以理解为比key的总数小，那么他肯定迭代不完你所有的数据。这个输出的cursor就是目前redis迭代到的位置，如果还想继续输出，可以把cursor替换成这个值，继续输出。如果为0，则表示整个库里都迭代完了
- 

>array_map和array_walk区别
- 关键点
- map    主要是为了得到你的回调函数处理后的新数组，要的是结果。
- walk   主要是对每个参数都使用一次你的回调函数，要的是处理的过程。
- walk   可以认为提供额外参数给回调函数，map不可以
- walk   主要是要对数组内的每个值进行操作，操作结果影响原来的数组
- map    主要是对数组中的值进行操作后返回数组，以得到一个新数组
- walk   可以没有返回值 
- map要有，因为要填充数组

>304状态码详解
- https://blog.csdn.net/Dongguabai/article/details/84323511
- 个人理解本地浏览器如果有缓存会自动带一些校验参数传递给服务器，服务器根据参数校验这个接口有没有变动过，有变动正常请求数据，返回200。没变动返回304，客户端展示缓存数据

>磁盘满了怎么查询
- du -h --max-depth=1
- du -h
- du -s /* | sort -nr
 命令查看那个目录占用空间大
- 执行 du -sh /usr/local/* | sort -r | head -n 10  查看 /usr/local 目录下占用空间较大的10个文件，并按照降序排列
- 
>php面试题
- https://www.cnblogs.com/gaowei521/p/10755237.html
- 1e3 是 科学计数法 实数的指数形式 为1乘以10的三次方，故‘1e3’=='1000'是成立的
-  <?php $a = "aabbzz"; $a++; echo $a; ?> $a = aabcaa.
-  字符串字母相加其实就是在末尾字母加一 如：$a = "a"; $a++;答应结果就是 b,$a=''aa';结果就是ab 故$a = "aabb";打印结果就是 aabc ,如$a = "aabbz";结果就是 aabca,因为Z是末尾字母故加一变为a,向前一位进一,b就变为c
-  写出一下程序的输出结果：<?php $a= 0.1; $b = 0.7;if($a+$b ==0.8){ echo true; }else{ echo false; } >
-  这里的考点有两个：1，echo false和true的值；2、浮点类型不能用于精确计算；首先浮点类型的数据不能用于计算，他会将浮点类型转为二进制，所以有一定的损耗，故它无限接近于0.8，也就是0.79999999...，所以echo 应该是个false；echo false；结果是空；echo true；结果是1；
-  用PHP写出显示客户端的IP和服务端的IP
-  echo $_SERVER[‘REMOTE_ADDR’];//客户端IP
-  echo gethostbyname(“www.baidu.com”)//服务端
-  快排代码
```
function quick_sort($array) {

    if (count($array) <= 1) return $array;

    $key = $array[0];

    $left_arr = array();

    $right_arr = array();

    for ($i=1; $i<count($array); $i++){

        if ($array[$i] <= $key)

            $left_arr[] = $array[$i];

        else

            $right_arr[] = $array[$i];

    }

    $left_arr = quick_sort($left_arr);

    $right_arr = quick_sort($right_arr);

    return array_merge($left_arr, array($key), $right_arr);

}
```
- 语句include和require的区别是什么？
- require是无条件包含，也就是如果一个流程里加入require，无论条件成立与否都会先执行require，当文件不存在或者无法打开的时候，会提示错误，并且会终止程序执行
- include有返回值，而require没有(可能因为如此require的速度比include快)，如果被包含的文件不存在的化，那么会提示一个错误，但是程序会继续执行下去
- PHP如何实现多继承吗
- 可以使用 interface 或 trait 实现 。
- 1.使用 interface 声明类不能被实例化，并且属性必须是常量，方法不能有方法体
- 2.trait 声明的类不能被实例化，由use引入，会覆盖父类的相同属性及方法，如果有多个use,那么按顺序下面的覆盖最上面的相同的属性及方法
- 如何修改session的生存时间
- 在php.ini 中设置 session.gc_maxlifetime = 1440 //默认时间
```
$lifeTime = 24 * 3600; // 保存一天

session_set_cookie_params($lifeTime);

session_start();
```
- 常见的 PHP 安全性攻击
- SQL注入：用户利用在表单字段输入SQL语句的方式来影响正常的SQL执行。
- 防止：
使用mysql_real_escape_string()过滤数据
手动检查每一数据是否为正确的数据类型
使用预处理语句并绑定变量
参数化SQL：是指在设计与数据库链接并访问数据时，在需要填入数值或数据的地方，使用参数 (Parameter) 来给值，用@或？来表示参数。
- XSS攻击 ：跨站点脚本攻击，由用户输入一些数据到你的网站，其中包括客户端脚本(通常JavaScript)。如果你没有过滤就输出数据到另一个web页面，这个脚本将被执行。
- 防止：为了防止XSS攻击，使用PHP的htmlentities()函数过滤再输出到浏览器。
- CSRF：跨站点请求伪造，是指一个页面发出的请求，看起来就像是网站的信任用户，但是是伪造的
- 防止：一般来说，确保用户来自你的表单，并且匹配每一个你发送出去的表单。有两点一定要记住：
对用户会话采用适当的安全措施，例如:给每一个会话更新id和用户使用SSL。
生成另一个一次性的令牌并将其嵌入表单，保存在会话中(一个会话变量)，在提交时检查它。 如laravel中的 _token
- 代码注入：代码注入是利用计算机漏洞通过处理无效数据造成的。问题出在，当你不小心执行任意代码，通常通过文件包含。写得很糟糕的代码可以允许一个远程文件包含并执行。如许多PHP函数，如require可以包含URL或文件名。
- 防止代码注入
过滤用户输入
在php.ini中设置禁用allow_url_fopen和allow_url_include。这将禁用require/include/fopen的远程文件
- 怎么保证促销商品不会超卖
- 使用了redis的队列来实现。将要促销的商品数量以队列的方式存入redis中，每当用户抢到一件促销商品则从队列中删除一个数据，确保商品不会超卖。这个操作起来很方便，而且效率极高，最终我们采取这种方式来实现
- 商城秒杀的实现
- 抢购、秒杀是如今很常见的一个应用场景，主要需要解决的问题有两个：1 高并发对数据库产生的压力2 竞争状态下如何解决库存的正确减少（"超卖"问题）
- 对于第一个问题，已经很容易想到用缓存来处理抢购，避免直接操作数据库，例如使用Redis。第二个问题，我们可以使用redis队列来完成，把要秒杀的商品放入到队列中，因为pop操作是原子的，即使有很多用户同时到达，也是依次执行，文件锁和事务在高并发下性能下降很快，当然还要考虑其他方面的东西，比如抢购页面做成静态的，通过ajax调用接口，其中也可能会出现一个用户抢多次的情况，这时候需要再加上一个排队队列和抢购结果队列及库存队列。高并发情况下，将用户进入排队队列，用一个线程循环处理从排队队列取出一个用户，判断用户是否已在抢购结果队列，如果在，则已抢购，否则未抢购，库存减1，写数据库，将用户入结果队列。
- 

>raft算法
- https://www.jianshu.com/p/dee17e12a537
- https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md

>阿里面试题
- https://github.com/0voice/interview_internal_reference
- 从 innodb 的索引结构分析，为什么索引的 key 长度不能太长
- key 太长会导致一个页当中能够存放的 key 的数目变少，间接导致索引树的页数目变多，索引层次增加，从而影响整体查询变更的效率
- MySQL 的数据如何恢复到任意时间点？
- 恢复到任意时间点以定时的做全量备份，以及备份增量的 binlog 日志为前提。恢复到任意时间点首先将全量备份恢复之后，再此基础上回放增加的 binlog 直至指定的时间点
- 

>Linux网络编程之select、poll、epoll的比较，以及epoll的水平触发(LT)和边缘触发(ET)
- https://www.cnblogs.com/heluan/p/9589086.html
- https://www.zhihu.com/question/28594409
- Linux的网络通信先后推出了select、poll、epoll三种模式。
- select有以下三个问题：
- （1）每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大。
- （2）同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大。
- （3）select支持的文件描述符数量太小了，默认是1024。
- poll解决了第三个问题，select保存描述符fd的数据结构是数组，poll改成了链表，突破了fd的个数限制。
- 但是第1和第2个问题依然存在。
- epoll在poll的基础上，又解决了前两个问题：
- （1）对第一个问题，epoll每次注册新的事件到epoll句柄中时（在epoll_ctl中指定EPOLL_CTL_ADD），会把所有的fd拷贝进内核，而不是在epoll_wait的时候重复拷贝。这样epoll保证了每个fd在整个过程中只会拷贝一次。
- （2）对第二个问题，epoll单独设置了一个就绪链表，当fd就绪(可读/可写)之后，放入就绪链表。epoll_wait只需要遍历就绪链表，而不需要遍历所有的fd，从而节省大量的CPU时间。
- epoll有LT和ET两种工作模式，默认工作模式是LT（水平触发），高速工作模式是ET（边缘触发）。
- LT是fd只要处于可读或可写状态，就会通知用户；ET只有不可读变为可读，或不可写变为可写之时，才会通知用户。
- ET对系统的调用，比LT要少得多，所以ET是高速工作模式，效率高很多。
- 用户使用ET模式时，读/写fd的时候，必须连续读/写完（直到返回EAGAIN错误）。否则如果未读/写完，系统会认为状态没有变化，就不会再重复通知，这样这个fd就死掉了。

>epoll的内核实现以及它的数据结构
- epoll_create:创建内核事件表用来存放描述符和事件。它的数据结构为：struct eventpoll。其中包括了两个重要成员，一个是红黑树，也就是内核事件表。另一个重要成员是用于存放就绪事件的队列。
- epoll_ctl:红黑树添加节点操作：ep_insert。红黑树移除节点操作：ep_remove。红黑树修改节点操作：ep_modify。每个节点都是一个描述符和事件的结构体。
- epoll_wait：负责收集就绪事件。
- 注意：关于epoll_wait是如何收集就绪事件的，大致是这样一个思路：添加事件和描述符时，注册回调函数。当描述符上有事件就绪时，把描述符和事件添加到队列中

>select 有描述符限制吗？是多少？
- https://blog.csdn.net/H2OzzZZ/article/details/89523601
- 关于文件描述符上限的这个问题，首先就要理解提问者所关注的重点，而且一般来说讨论的是select本身的FD_SETSIZE=1024这个限制，如果是选择题poll和epoll应该没有上限，但如果是问答，最好能讲清楚
- 