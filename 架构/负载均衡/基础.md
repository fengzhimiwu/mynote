### 什么是负载均衡

> **负载均衡**，英文名称为**Load Balance**，其含义就是指将负载（工作任务）进行平衡、分摊到多个操作单元上进行运行，例如FTP服务器、Web服务器、企业核心应用服务器和其它主要任务服务器等，从而协同完成工作任务。
>
> **是解决高性能，单点故障（高可用），扩展性（水平伸缩）的终极解决方案。**

> 负载均衡构建在原有网络结构之上，它提供了一种透明且廉价有效的方法扩展服务器和网络设备的带宽、加强网络数据处理能力、增加吞吐量、提高网络的可用性和灵活性。



### 负载均衡实现

负载均衡实现分为：软件、硬件两种方式

**硬件：**

> 常见的硬件有比较昂贵的NetScaler、F5、Radware和Array等商用的负载均衡器
> 也有类似于LVS、Nginx、HAproxy的基于Linux的开源的负载均衡策略
> 商用负载均衡里面NetScaler从效果上比F5的效率上更高
> 商用负载均衡由于可以建立在四~七层协议之上，适用面更广所以有其不可替代性
> 优点：有专业的维护团队来对这些服务进行维护
> 缺点：价格昂贵，
> 对于规模较小的网络服务来说暂时还没有需要使用
>
> https://blog.csdn.net/weixin_41440282/article/details/81141609

**软件：**

LVS：
    1、抗负载能力强、是工作在网络4-7层之上仅作分发之用，没有流量的产生；
    2、配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率；
    3、工作稳定，自身有完整的双机热备方案；
    4、无流量，保证了均衡器IO的性能不会收到大流量的影响；
    5、应用范围比较广，可以对所有应用做负载均衡；
    6、LVS需要向IDC多申请一个IP来做Visual IP，因此需要一定的网络知识，所以对操作人的要求比较高。

Nginx：
    1、工作在网络的7层之上，可以针对http应用做一些分流的策略，比如针对域名、目录结构；
    2、Nginx对网络的依赖比较小；
    3、Nginx安装和配置比较简单，测试起来比较方便；
    4、也可以承担高的负载压力且稳定，一般能支撑超过1万次的并发；
    5、Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，
       并且会把返回错误的请求重新提交到另一个节点，不过其中缺点就是不支持url来检测；
    6、Nginx对请求的异步处理可以帮助节点服务器减轻负载；
    7、Nginx能支持http和Email，这样就在适用范围上面小很多；
    8、不支持Session的保持、对Big request header的支持不是很好，
    另外默认的只有Round-robin和IP-hash两种负载均衡算法。

HAProxy：
    1、HAProxy是工作在网络4-7层之上。
    2、能够补充Nginx的一些缺点比如Session的保持，Cookie的引导等工作
    3、支持url检测后端的服务器出问题的检测会有很好的帮助。
    4、更多的负载均衡策略比如：
			动态加权轮循(Dynamic Round Robin)，
       	 加权源地址哈希(Weighted Source Hash)，
       	 加权URL哈希和加权参数哈希(Weighted Parameter Hash)已经实现
    5、单纯从效率上来讲HAProxy更会比Nginx有更出色的负载均衡速度。
    6、HAProxy可以对Mysql进行负载均衡，对后端的DB节点进行检测和负载均衡。

DNS:

​	通过配置域名多个a记录ip

​	优点：

1. 将负载均衡的工作丢给了DNS服务器去做，省去了网站管理人员的维护工作
2. 对于真实地址的服务器，不需要做任何的配置
3. 简单易用，成本低，而且方便灵活
4. 服务器可以放在任何的地方
5. 同时，DNS服务还可以做基于地理位置的解析，可以让一个距离最近的服务器的IP地址放回，提高性能

   缺点：

​	1.DNS服务是多级的，当某一台真实服务器下线，修改DNS服务器记录，需要一段时间生效，容易导致访问失败

​	2.DNS服务器和真机是独立分开的，无法监测真机的运行状态，负载均衡效果不好

​    3.DNS服务器之间同步数据需要额外的网络开销

https://blog.csdn.net/bpb_cx/article/details/82771168



**负载均衡算法**

负载均衡服务器在决定将请求转发到具体哪台真实服务器的时候，是通过负载均衡算法来实现的。负载均衡算法，是一个负载均衡服务器的核心。

负载均衡算法可以分为两类：**静态负载均衡算法**和**动态负载均衡算法**。

静态负载均衡算法包括：

- **轮询（Round Robin）：**顺序循环将请求一次顺序循环地连接每个服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从顺序循环队列中拿出，不参加下一次的轮询，直到其恢复正常。
- **比率（Ratio）：**给每个服务器分配一个加权值为比例，根椐这个比例，把用户的请求分配到每个服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配, 直到其恢复正常。
- **优先权（Priority）：**给所有服务器分组,给每个组定义优先权，BIG-IP 用户的请求，分配给优先级最高的服务器组（在同一组内，采用轮询或比率算法，分配用户的请求）；当最高优先级中所有服务器出现故障，BIG-IP 才将请求送给次优先级的服务器组。这种方式，实际为用户提供一种热备份的方式。

动态负载均衡算法包括: 

- **最少的连接方式（Least Connection）：**传递新的连接给那些进行最少连接处理的服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配, 直到其恢复正常。
- **最快模式（Fastest）：**传递连接给那些响应最快的服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。
- **观察模式（Observed）：**连接数目和响应时间以这两项的最佳平衡为依据为新的请求选择服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。
- **预测模式（Predictive）：**BIG-IP利用收集到的服务器当前的性能指标，进行预测分析，选择一台服务器在下一个时间片内，其性能将达到最佳的服务器相应用户的请求。(被BIG-IP 进行检测)
- **动态性能分配(Dynamic Ratio-APM)：**BIG-IP 收集到的应用程序和应用服务器的各项性能参数，动态调整流量分配。
- **动态服务器补充(Dynamic Server Act.)：**当主服务器群中因故障导致数量减少时，动态地将备份服务器补充至主服务器群。
- **服务质量(QoS）：**按不同的优先级对数据流进行分配。
- **服务类型(ToS)：**按不同的服务类型（在Type of Field中标识）负载均衡对数据流进行分配。
- **规则模式：**针对不同的数据流设置导向规则，用户可自行。